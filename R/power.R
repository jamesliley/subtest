plr_power=function(power=0.9,pcut,Za,Zd=abs(rnorm(length(Za))),model) {
  
  # Fit two-gaussian model to Z_d to estimate tau and pi2  
  f1=fit.em(Z[,1],weights=weights,pi0_init=0.99,sigma_init=3)
  
  pi0=f1$pi0
  tau=f1$sigma
  
  # Fit two-gaussian model to Z_a conditional on pi2 to estimate sigma_2
  sigma=fit.em1(Z[,1],weights=weights,pi0=pi0)

}

##' Estimate the values of ... and ... suggested by a set of \code{\link{Zd}} and \code{\link{Za}} values.
dataset_values=function(Za,Zd) {}


##' Compute number of cases in order that observed value of sigma (that is, \code{tau}, \code{s2}) reaches a given value. 
##' 
##' The observed standard deviation depends on the underlying distribution of population odds ratios; that is, odds ratios between population minor allele frequencies of the causative and protective alleles. This can be estimated using the function \code{\link{dataset_values}}
##' 
##' This function computes the number of cases in two groups necessary to reach a given observed standard deviation (\code{\link{sig_o}}) for effect sizes between then (\code{tau} or \code{s2}). The two groups correspond to either the number of cases and the number of controls (in which case \code{\link{sig_o}}=\code{s2}) or the number of cases in each subgroup (in which case \code{\link{sig_o}}=\code{tau}).
##' 
##' @title npower
##' @param sig_u underlying standard deviation of odds ratio distribution. Estimable using function \code{\link{dataset_values}}. Set to NULL to compute from other values.
##' @param n1 number of cases in subgroup/group 1. Set to NULL to compute conditional on other values. If both \code{\link{n1}} and \code{\link{n2}} are NULL, computes required number of cases conditional on \code{\link{n1}}=\code{\link{n2}}
##' @param n2 number of cases in subgroup/group 2. Set to NULL to compute conditional on other values. If both \code{\link{n1}} and \code{\link{n2}} are NULL, computes required number of cases conditional on \code{\link{n1}}=\code{\link{n2}}
npower=function(sig_u=NULL,sig_o=NULL,n1=NULL,n2=NULL) {

if ((is.null(sig_u) & is.null(n1) & is.null(n2) & is.null(sig_o)) | (!is.null(sig_u) & !is.null(n1) & !is.null(n2) & !is.null(sig_o))) stop("Only one of sig_u, sig_o, OR one or both of n1, n2 must be null.")

if (is.null(sig_u)) sig_u=sqrt(3*(n1+n2)*(1+(sig_o^2))/(n1*n2))
if (is.null(sig_o)) sig_o=sqrt(1+(n1*n2*(sig_u^2)/(3*(n1+n2))))
if (is.null(n1) & !is.null(n2)) n1=3*n2*((sig_o^2) - 1)/((n2*(sig_u^2))-(3*((sig_o^2) - 1)))
if (is.null(n2) & !is.null(n1)) n2=3*n1*((sig_o^2) - 1)/((n1*(sig_u^2))-(3*((sig_o^2) - 1)))
if ((n1<0) | (n2<0)) {
 warning("Value of parameter sig_o cannot be reached given this value of sig_u. Assuming n1=n2")
 n1=NULL; 
 n2=NULL
}


if (is.null(n1) & is.null(n2)) {
  n1=6*((sig_o^2)-1)/(sig_u^2)
  n2=n1
}

c(sig_u,sig_o,round(n1),round(n2))
}


##' General power calculation method for PLR. 
##' 
##' Power of the PLR method depends on the number of SNPs in category 3 (\code{\link{n3}}), and the marginal variances in category 3 of \eqn{Z_{a}}{Z_a} (\code{\link{s2}}) and \eqn{Z_{a}}{Z_a} (\code{\link{tau}}). Given a required power and p-value, 
##' 
##' 
##' 
##' Function to estimate power to reject the null hypothesis at significance \code{\link{p}} given underlying parameters \code{\link{pi2}}, \code{\link{s2}}, \code{\link{tau}} and \code{\link{rho}}.
##' 
##' @param ll object of class \code{\link{lm}}. Given simulated values, \code{\link{ll}} should be generated by a function of the form \code{ll=lm(I(log(1+plr)~ pi2+ poly(s2,2)+poly(tau,2) + I(pi2*s2) + I(pi2*tau))))}. Simulated values should be from uncorrelated observations on unweighted SNPs, so the asymptotic distribution of PLR is mixture-chi^2.
##' 
##' Power also depends on parameters \code{s1}, the marginal standard deviation for \eqn{Z_{a}}{Z_a} in category 2, \code{pi1}, the proportion of SNPs in category 2, and \code{rho}, the correlation between \eqn{Z_{a}}{Z_a} and \eqn{Z_{d}}{Z_d} in category 3, but the influence on power from these variables is small.
##' 
##' @param p significance level at which to estimate power
##' @param pi2 underlying parameter for which power is to be estimated. Corresponds to number of SNPs in category 3
##' @param s2 underlying parameter for which power is to be estimated. Marginal standard deviation for \eqn{Z_a}{Z_{a}} in category 3
##' @param tau underlying parameter for which power is to be estimated. Marginal standard deviation for \eqn{Z_d}{Z_{d}} in category 3
##' @param rho underlying parameter for which power is to be estimated. Correlation between \eqn{Z_a}{Z_{a}} and \eqn{Z_d}{Z_{d}} in category 3
power=function(power=NULL,p=NULL,n3=NULL,s2=NULL,tau=NULL)  {

if (is.null(p)+ is.null(power) +is.null(n3) + is.null(s2) + is.null(tau) != 1) stop("All but one of parameters p, power, n3, s2, and tau must be set")
  
data("power_simulations.RData")
  
if (is.null(power)) {
  ptab=maketab(power_simulations,p)
  power=power_interpolate(c(n3,s2,tau),ptab)
}

if (is.null(n3)) {
  ptab=maketab(power_simulations,p)
  nrange=range(ptab[,1])
  if (power_interpolate(c(nrange[1],tau,s2),ptab)>power) n3=nrange[1] else {
    if (power_interpolate(c(nrange[2]-1,tau,s2),ptab)<power) n3=Inf else { 
      n3=round(uniroot(function(x) power_interpolate(c(x,tau,s2),ptab)-power,c(nrange[1],nrange[2]-1))$root)
    }
  }
}


if (is.null(tau)) {
  ptab=maketab(power_simulations,p)
  nrange=range(ptab[,2])
  if (power_interpolate(c(n3,nrange[1],s2),ptab)>power) tau=nrange[1] else {
    if (power_interpolate(c(n3,0.99*nrange[2],s2),ptab)<power) tau=Inf else { 
      n3=uniroot(function(x) power_interpolate(c(n3,x,s2),ptab)-power,c(nrange[1],0.99*nrange[2]))$root
    }
  }
}

if (is.null(s2)) {
  ptab=maketab(power_simulations,p)
  nrange=range(ptab[,3])
  if (power_interpolate(c(n3,tau,nrange[1]),ptab)>power) s2=nrange[1] else {
    if (power_interpolate(c(n3,tau,0.99*nrange[2]),ptab)<power) s2=Inf else { 
      n3=uniroot(function(x) power_interpolate(c(n3,tau,x),ptab)-power,c(nrange[1],0.99*nrange[2]))$root
    }
  }
}

c(power,p,n3,s2,tau)

}



##' Given a set of simulations for power calculations, tabulate power as a function of values of the number of SNPs in category 3 (n3), sigma2, and tau. 
##' 
##' Each row of the matrix of simulations must have length >25, in which the first 18 elements are identical to those from general simulation output (ie: likelihood under H1, likelihood under H0, correcting factor, number of iterations to fit H1 model, number of iterations to fit H0 model, random seed, parameters of H0 model, parameters of H1 model) followed by: number of SNPs in category 1, number of SNPs in category 2, number of SNPs in category 3, true value of tau, true value of sigma1, true value of sigma2, true value of rho. Other matrix columns are ignored.
##' 
##' Simulations must be such that the asymptotic distribution of PLR under the null is a mixture of chi^2 distributions with one and two degrees of freedom, where distributions have equal weights.
##' 
##' @title maketab
##' @param sims matrix of simulation results. See above for necessary form.
##' @param p tabulate power to detect this level of significance
##' @return matrix with dimensions n x 4; each row takes the form: n3, tau, sigma2, power.
maketab=function(sims,p) {

if (dim(sims)[2]<25) stop("Each row of matrix of simulation results must have length >25, and be of the form: likelihood under H1, likelihood under H0, correcting factor, number of iterations to fit H1 model, number of iterations to fit H0 model, random seed, parameters of H0 model, parameters of H1 model, true value of pi0, true value of pi1, true value of pi2, true value of tau, true value of sigma1, true value of sigma2, true value of rho")

plr=sims[,2]-sims[,1]-sims[,3]
  
pmc=function(x) 0.5*pchisq(2*x,df=1,lower.tail=FALSE) + 0.5*pchisq(2*x,df=2,lower.tail=FALSE) - p
plr_cut=uniroot(pmc,c(0,200))$root # cutoff on PLR corresponding to p value

pass=plr>plr_cut

pi2v=sort(unique(sims[,21]))
tauv=sort(unique(sims[,22]))
s2v=sort(unique(sims[,24]))

tab=c()
for (i in 1:length(pi2v)) {
  for (j in 1:length(tauv)) {
    for (k in 1:length(s2v)) {
      ww=which(sims[,21]==pi2v[i] & sims[,22]==tauv[j] & sims[24]==s2v[k])
      if (length(ww)<10) warning(paste0("Few or no simulations available with n3=",pi2v[i],", tau=",tauv[j],", sigma2=",s2v[k]))
      if (length(ww)>1) power=mean(pass[ww]) else power=NA
      tab=rbind(tab,c(pi2v[i],tauv[j],s2v[k],power))
    }
  }
}
tab
}



##' Given a table of observed power values from simulations at a range of parameter sets, estimates power at a new set of parameters by linear interpolation. Table of power values must be complete.
##' 
##' @title power_interpolate
##' @param x vector of values n3 (number of SNPs in category 3),tau,sigma2,rho at which to estimate power
##' @param ptab matrix of simulations; each row n3, tau, sigma2, power. 
##' @return estimate of power at new set of parameter values
power_interpolate=function(x,ptab) {

# Range of values of pi2, tau and sigma2
pi2_vals=sort(unique(ptab[,1]))
tau_vals=sort(unique(ptab[,2]))
s2_vals=sort(unique(ptab[,3]))

# don't try to extrapolate
if (x[1]<range(pi2_vals)[1] | x[1]>range(pi2_vals)[2]) stop("Value of n3 outside simulated range")
if (x[2]<range(tau_vals)[1] | x[2]>range(tau_vals)[2]) stop("Value of tau outside simulated range")
if (x[3]<range(s2_vals)[1] | x[3]>range(s2_vals)[2]) stop("Value of s2 outside simulated range")

# find cuboid of points (p1,p2) x (t1,t2) x (s1,s2) containing x
p_ind=max(which(pi2_vals<=x[1])); p1=pi2_vals[p_ind]; p2=pi2_vals[p_ind+1]
t_ind=max(which(tau_vals<=x[2])); t1=tau_vals[t_ind]; t2=tau_vals[t_ind+1]
s_ind=max(which(s2_vals<=x[3])); s1=s2_vals[s_ind]; s2=s2_vals[s_ind+1]

# find which of five tetrahedrons contains x. Not unique.
k1=c(p1,t1,s1); k2=c(p2,t1,s1); k3=c(p1,t2,s1); k4=c(p1,t1,s2)
k5=c(p1,t2,s2); k6=c(p2,t1,s2); k7=c(p2,t2,s1); k8=c(p2,t2,s2)
if (intet(x,k1,k2,k3,k4)) {; x1=k1; x2=k2; x3=k3; x4=k4; }
if (intet(x,k2,k4,k6,k8)) {; x1=k2; x2=k4; x3=k6; x4=k8; }
if (intet(x,k3,k4,k5,k8)) {; x1=k3; x2=k4; x3=k4; x4=k8; }
if (intet(x,k2,k3,k7,k8)) {; x1=k2; x2=k3; x3=k7; x4=k8; }
if (intet(x,k2,k3,k4,k8)) {; x1=k2; x2=k3; x3=k4; x4=k8; }

# power values at corners of tetrahedron
w1=which(ptab[,1]==x1[1] & ptab[,2]==x1[2] & ptab[,3]==x1[3]); if (length(w1)!=1) stop("Parameter x outside interpolation range") else y1=ptab[w1,4]
w2=which(ptab[,1]==x2[1] & ptab[,2]==x2[2] & ptab[,3]==x2[3]); if (length(w2)!=1) stop("Parameter x outside interpolation range") else y2=ptab[w2,4]
w3=which(ptab[,1]==x3[1] & ptab[,2]==x3[2] & ptab[,3]==x3[3]); if (length(w3)!=1) stop("Parameter x outside interpolation range") else y3=ptab[w3,4]
w4=which(ptab[,1]==x4[1] & ptab[,2]==x4[2] & ptab[,3]==x4[3]); if (length(w4)!=1) stop("Parameter x outside interpolation range") else y4=ptab[w4,4]
y=c(y1,y2,y3,y4)

# find linear interpolant across tetrahedron, and evaluate at x.
t(c(x,1)) %*% (solve(cbind(rbind(x1,x2,x3,x4),c(1,1,1,1))) %*% t(t(y)))

}



##' Tests if a point is inside a tetredron
##' 
##' @title intet
##' @param x point to be tested (three element vector)
##' @param p1 first vertex of tetrahedron (three element vector)
##' @param p2 second vertex of tetrahedron (three element vector)
##' @param p3 third vertex of tetrahedron (three element vector)
##' @param p4 fourth vertex of tetrahedron (three element vector)
##' @return TRUE/FALSE
##' @examples 
##'  p1=c(0,0,2); p2=c(0,2,0); p3=c(2,0,0); p4=c(3,3,3); x=c(2,2,2); y=c(1,1,0)
##'  intet(x,p1,p2,p3,p4)
##'  intet(y,p1,p2,p3,p4)
intet=function(x,p1,p2,p3,p4) {
sg=round(det(cbind(rbind(p1,p2,p3,p4),c(1,1,1,1)))) # 'round' is because R does not handle singular matrices well.
d1=round(det(cbind(rbind(x,p2,p3,p4),c(1,1,1,1))))
d2=round(det(cbind(rbind(p1,x,p3,p4),c(1,1,1,1))))
d3=round(det(cbind(rbind(p1,p2,x,p4),c(1,1,1,1))))
d4=round(det(cbind(rbind(p1,p2,p3,x),c(1,1,1,1))))
!all(range(sign(c(sg,d1,d2,d3,d4)))==c(-1,1))
}



if (FALSE) {
# Generate linear model

# Read power simulation matrix
sim_store="~/Subtypes/Common/simulation/" ####################################### temporary
lrp=read.table(paste0(sim_store,"LRp")); 
ya=sort(c(qchisq((1:1000)/1001,df=1),qchisq((1:1000)/1001,df=2)))
cut=quantile(ya,0.95)/2 # LR cutoff for significance

plr=lrp[,2]-lrp[,1]-lrp[,3]; 
pass=plr>cut; 
plrt=plr; plrt[which(plrt<0)]=0; plrt=log(1+plrt)

# true values
pi2=lrp[,21]; pi1=lrp[,20]; s1=lrp[,23]; s2=lrp[,24];tau=lrp[,22]; rho=lrp[,25]
ll=lm(plrt ~  pi2+ poly(s2,2,raw=TRUE)+poly(tau,2,raw=TRUE) + I(pi2*s2) + I(pi2*tau))



# fitted values
pi2=1-lrp[,13]-lrp[,14]; pi1=lrp[,14]; s1=lrp[,16]; s2=lrp[,17]; tau=lrp[,15]; rho=lrp[,18]/(s2*tau)
ll=lm(plrt ~  pi2+ poly(s2,2,raw=TRUE)+poly(tau,2,raw=TRUE) + I(pi2*s2) + I(pi2*tau))


load("~/Subtypes/Common/data/power_model.RData") # get power matrix

sx=rep(0,dim(pmat)[1])
for (i in 1:length(sx)) sx[i]=mean(gg$fitted.values[which(pi2==pmat[i,1] & tau==pmat[i,2] & s2==pmat[i,3] & rho==pmat[i,4])])

g2=glm(power~pi0+tau+sigma2+rho,data=pmat)


plot(pmat[,5],sx)
points(pmat[,5],g2$fitted.values,col="blue")

}

##' Fit a specific two Guassian mixture distribution to a set of Z values.
##'
##' Assumes 
##' Z ~ N(0,1) with probability  \code{\link{pi0}}, Z ~ N(0,1 + \code{\link{sigma}}^2) with probability 1-\code{\link{pi0}}
##'
##' We define 'true' Z scores as the Z scores that would be obtained if MAF for both groups exactly matched the corresponding MAFs in the population, or equivalently the expected values of Z scores. If 'true' Z scores are distributed following a 'spike and tail' model of 0 with probability \code{\link{pi0}} and N(0,\code{\link{sigma}}^2) with probability 1-\code{\link{pi0}}, then observed Z scores follow the above distribution.
##' @title fit.em
##' @param Z numeric vector of observed data
##' @param sigma_init initial value for \code{\link{sigma}}
##' @param pi0_init initial value for \code{\link{pi0}}
##' @param tol how small a change lhood prompts continued optimization
##' @param maxit maximum number of iterations
##' @return a list containing fitted \code{\link{pi0}}, fitted \code{\link{sigma}}, and a record of fitted parameters at eachs stage of the E-M algorithm.
##' @export
##' @author Chris Wallace, James Liley
##' @examples
##' sigma <- 2
##' pi0 <- 0.8
##' n <- 10000; n0=round(pi0*n); n1=n-n0
##' Z <- c(rnorm(n0,0,1),rnorm(n1,0,sqrt(1+ (sigma^2))))
##' fit<-fit.em(Z)
##' fit$pi0
##' fit$sigma
##' fit$history
fit.em <- function(Z,weights=rep(1,length(Z)), pi0_init=0.9,sigma_init=2,tol=1e-4,verbose=TRUE,maxit=1e4) {
  
  ## probabilities of group0, group1 membership
  p <- c(pi0_init,1-pi0_init)

  px <- matrix(p,length(Z),2,byrow=TRUE)
  
  ## parameter vector
  pars <- c(pi0_init,sigma_init)
  
  
  pars.fail <- function(pars) if ((pars[1]<0) | (pars[1]>1) | (pars[2]<0)) return(TRUE) else return(FALSE)
  
  ## likelihood for first group
  lh1=function(pi) pi*dnorm(Z)
  
  ## likelihood for second group
  lh2=function(pi,sigma) pi*dnorm(Z,sd=sigma)
  
  ## likelihood function to be maximized
  lhood <- function(pars, sumlog=TRUE) {
    e=lh1(pars[1]) + lh2(1-pars[1],pars[2]) 
    e[which(e==0)] <- 1e-64
    e[which(is.infinite(e))] <- 1e64
    if(sumlog) return(sum(weights*log(e))) else return(-e)
  }
  
  nit <- 1
  df <- 1
  value <- matrix(NA,maxit,3,dimnames=list(NULL,c("pi0","sigma","lhood")))
  value[nit,] <- c(pars, lhood(pars))
  while(df>tol & nit<maxit) {
    
    nit <- nit+1
    
    ## E step
    px[,1]=lh1(pars[1]);
    px[,2]=lh2(1-pars[1],pars[2])
    
    px <- px/rowSums(px) ## normalise
    px[is.nan(px)] <- 0
    
    ## M step
    pars[1] = mean(px[,1])
    pars[2] <- max(1, sqrt(sum(weights* px[,2] * Z^2 ) / sum(weights*px[,2]) ))
    value[nit,] <- c(pars, lhood(pars))
    df <- abs(value[nit,3] - value[nit-1,3])
    
  }
  return(list(pi0=pars[1], sigma=pars[2],
              history=value[1:nit,]))
}






##' Fit a specific two Guassian mixture distribution to a set of Z values, as for \code{\link{fit.em}} but fixing \code{pi0} at the value of \code{\link{pi0_init}}, only fitting \code{sigma}.
##'
##' Assumes 
##' Z ~ N(0,1) with probability  \code{\link{pi0}}, Z ~ N(0,1 + \code{\link{sigma}}^2) with probability 1-\code{\link{pi0}}
##'
##' @title fit.em1
##' @param Z numeric vector of observed data
##' @param sigma_init initial value for \code{\link{sigma}}
##' @param pi0_init value for \code{\link{pi0}}
##' @param tol how small a change lhood prompts continued optimization
##' @param maxit maximum number of iterations
##' @return a list containing fitted \code{\link{pi0}}, fitted \code{\link{sigma}}, and a record of fitted parameters at eachs stage of the E-M algorithm.
##' @export
##' @author Chris Wallace, James Liley
##' @examples
##' sigma <- 2
##' pi0 <- 0.8
##' n <- 10000; n0=round(pi0*n); n1=n-n0
##' Z <- c(rnorm(n0,0,1),rnorm(n1,0,sqrt(1+ (sigma^2))))
##' fit<-fit.em(Z)
##' fit$pi0
##' fit$sigma
##' fit$history
fit.em1 <- function(Z,weights=rep(1,length(Z)), pi0=0.95,sigma_init=2,tol=1e-4,verbose=TRUE,maxit=1e4) {
  
## likelihood for first group
lh1=function(pi) pi*dnorm(Z)

## likelihood for second group
lh2=function(pi,sigma) pi*dnorm(Z,sd=sigma)

## likelihood function to be maximized
lhood <- function(pi,sigma, sumlog=TRUE) {
  e=lh1(pi) + lh2(1-pi,sigma) 
  e[which(e==0)] <- 1e-64; e[which(is.infinite(e))] <- 1e64
  if(sumlog) return(sum(weights*log(e))) else return(e)
}

## Derivative of likelihood function with respect to sigma
dlhood=function(pi,sigma) {

num=lh2(1-pi,sigma)* (-(1/sigma) + ((Z^2)/(sigma^3)))
denom=lhood(pi,sigma,sumlog=FALSE)
sum(weights* (num/denom))
}

# Solve
range=c(1,10)
if (dlhood(pi0,range[1])*dlhood(pi0,range[2])<0) sigma=uniroot(function(x) dlhood(pi0,x),range)$root else sigma=1
return(sigma)
}
